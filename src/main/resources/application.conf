// Application configuration file
app {

  // default Spark timezone
  sparkTimezone = "GMT"

 // generation module configuration
  featureGeneration {
    // default Spark debug level
    sparkDebugLevel = "WARN"
    // user session threshold, if user inactive for this amount of time (in seconds)
    // a new session starts with next action
    sessionThreshold = 300
    // maximal allowed speed in m/s for GPS data validation
    maxSpeed = 343.0
    // default write mode for results
    writeMode = "error"
  }

  // preprocessing module configuration
  features {
    sparkDebugLevel = "WARN"
    // the number of partitions for data processing
    processingPartitions = 1000
    // the number of output partitions
    outputPartitions = 500
    // delimiter type for seed data
    seedDataDelimiter = "|"
    // boolean flag for header in seed data (false - no header)
    seedDataHeader = "false"
    // default write mode for results
    writeMode = "error"
    // percentile of outliers to discard. Specified the fraction of the most
    // outlying records that is discarded for each group
    discardOutliersFraction = 0.1
    // dictionry size for term-frequency matrix of app usage (number of hash buckets, prefferably the power of 2)
    tfDictionarySize = 16384
  }

  // modelling module configuration
  modelTraining {
    sparkDebugLevel = "WARN"

    // ---------- general model training parameters ----------
    // the minimal number of RTB log records for device to be considered valid for modelling and prediction
    minActivity = 50
    // the number of features for Chi-square feature selection of term-frequency features
    topTfIdf = 50
    // the number of folds for cross-validation (parameter tuning)
    CVFolds = 3
    // the fraction of a dataset to use for model train (the rest is used as a test set for the final model evaluation)
    trainSetFraction = 0.8
    // the fraction of a dataset to use for train split validation (tree ensemble models)
    validationSetFraction = 0.8

    // ---------- linear model parameters ----------
    // the maximal number of train iterations
    maxIterLinear = 100
    // l2 regularization tuning parameter grid
    regularizationLinear = [1.0, 0.5, 0.2, 0.05]
    // l1 regularization tuning parameter grid
    elasticNetLinear = [0.5, 0.2, 0.07, 0.01]

    // ---------- Bayesian model parameters ----------
    // regularization tuning parameter grid
    smoothingBayes = [10.0, 5.0, 1.0]

    // ---------- Random Forest model parameters ----------
    // maximal tree depth regularization tuning parameter grid
    maxDepthRandomForest = [3, 5, 7, 10]
    // the maximal number of trees in the model
    maxTreesRandomForest = 100

    // ---------- Gradient Boosting model parameters ----------
    // the maximal number of train iterations
    maxIterGradientBoosted = 50
    // maximal tree depth regularization tuning parameter grid
    maxDepthGradientBoosted = [3, 5, 8]
  }

  // prediction module configuration
  prediction {
    sparkDebugLevel = "WARN"
  }

}
